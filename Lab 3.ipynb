{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import imageio\n",
    "import random\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder):\n",
    "    available_classes = os.listdir(folder)\n",
    "    data = []\n",
    "    for img_class in available_classes:\n",
    "        images = os.listdir(folder + '/' + img_class)\n",
    "        for image in images:\n",
    "            path = folder + '/' + img_class + '/' + image\n",
    "            try:\n",
    "                img = imageio.imread(path).reshape(28, 28, 1)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "            data.append((img / 255., available_classes.index(img_class)))\n",
    "    return data, available_classes\n",
    "\n",
    "def remove_duplicates(train, val, test):\n",
    "    index = {}\n",
    "    for img, cls in val + test:\n",
    "        if cls not in index:\n",
    "            index[cls] = {}\n",
    "\n",
    "        img = np.array(img.reshape(28 * 28))\n",
    "        val_h = sum(img)\n",
    "        if val_h not in index[cls]:\n",
    "            index[cls][val_h] = []\n",
    "        index[cls][val_h].append(img)\n",
    "        \n",
    "    duplicate_ids = []\n",
    "    for i, img_cls in enumerate(train):\n",
    "        img, cls = img_cls\n",
    "        img = list(np.array(img.reshape(28 * 28)))\n",
    "        h = sum(img)\n",
    "        if h in index[cls]:\n",
    "            candidates = index[cls][h]\n",
    "            for candidate in candidates:\n",
    "                if list(candidate) == img:\n",
    "                    duplicate_ids.append(i)\n",
    "                    break\n",
    "                \n",
    "    for data_id in reversed(duplicate_ids):\n",
    "        del train[data_id]\n",
    "        \n",
    "def unzip(tuples):\n",
    "    first = [t[0] for t in tuples]\n",
    "    second = [t[1] for t in tuples]\n",
    "    return np.array(first), np.array(second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_mnist = \"../Lab 1/notMNIST_large\"\n",
    "small_mnist = \"../Lab 1/notMNIST_small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find a format to read the specified file in mode 'i'\n",
      "Could not find a format to read the specified file in mode 'i'\n"
     ]
    }
   ],
   "source": [
    "data, available_classes = load_data(small_mnist)\n",
    "\n",
    "size = len(data)\n",
    "train_size = int(size * 0.95)\n",
    "val_size = int(train_size * 0.05)\n",
    "\n",
    "random.shuffle(data)\n",
    "\n",
    "train_data = data[:train_size]\n",
    "test_data = data[train_size:]\n",
    "val_data = train_data[:val_size]\n",
    "train_data = train_data[val_size:]\n",
    "\n",
    "remove_duplicates(train_data, val_data, test_data)\n",
    "\n",
    "train_x, train_y = unzip(train_data)\n",
    "val_x, val_y = unzip(val_data)\n",
    "test_x, test_y = unzip(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 22, 22, 28)        1400      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 9, 9, 28)          153692    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2268)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                145216    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 300,958\n",
      "Trainable params: 300,958\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, Model, Input, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, Flatten\n",
    "\n",
    "num_classes = len(available_classes)\n",
    "model = Sequential([\n",
    "    Conv2D(28, (7, 7), input_shape=(28, 28, 1,)),\n",
    "    Conv2D(28, (14, 14)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "    \n",
    "model.compile(optimizer=\"rmsprop\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16626 samples, validate on 889 samples\n",
      "Epoch 1/20\n",
      "16626/16626 [==============================] - 54s 3ms/sample - loss: 0.6189 - accuracy: 0.8217 - val_loss: 0.4319 - val_accuracy: 0.8628\n",
      "Epoch 2/20\n",
      "16626/16626 [==============================] - 53s 3ms/sample - loss: 0.4078 - accuracy: 0.8831 - val_loss: 0.4168 - val_accuracy: 0.8875\n",
      "Epoch 3/20\n",
      "16626/16626 [==============================] - 53s 3ms/sample - loss: 0.3518 - accuracy: 0.9006 - val_loss: 0.5660 - val_accuracy: 0.8358\n",
      "Epoch 4/20\n",
      "16626/16626 [==============================] - 53s 3ms/sample - loss: 0.3089 - accuracy: 0.9116 - val_loss: 0.4556 - val_accuracy: 0.8763\n",
      "Epoch 5/20\n",
      "16626/16626 [==============================] - 53s 3ms/sample - loss: 0.2826 - accuracy: 0.9230 - val_loss: 0.4029 - val_accuracy: 0.8875\n",
      "Epoch 6/20\n",
      "16626/16626 [==============================] - 53s 3ms/sample - loss: 0.2594 - accuracy: 0.9270 - val_loss: 0.4146 - val_accuracy: 0.9100\n",
      "Epoch 7/20\n",
      "16626/16626 [==============================] - 53s 3ms/sample - loss: 0.2286 - accuracy: 0.9361 - val_loss: 0.4936 - val_accuracy: 0.9021\n",
      "Epoch 8/20\n",
      "16626/16626 [==============================] - 53s 3ms/sample - loss: 0.2203 - accuracy: 0.9413 - val_loss: 0.4873 - val_accuracy: 0.8920\n",
      "Epoch 9/20\n",
      "16626/16626 [==============================] - 53s 3ms/sample - loss: 0.2051 - accuracy: 0.9436 - val_loss: 0.5763 - val_accuracy: 0.8718\n",
      "Epoch 10/20\n",
      "16626/16626 [==============================] - 53s 3ms/sample - loss: 0.1794 - accuracy: 0.9507 - val_loss: 0.5493 - val_accuracy: 0.9123\n",
      "Epoch 11/20\n",
      "16626/16626 [==============================] - 53s 3ms/sample - loss: 0.1736 - accuracy: 0.9539 - val_loss: 0.6211 - val_accuracy: 0.8988\n",
      "Epoch 12/20\n",
      "16626/16626 [==============================] - 53s 3ms/sample - loss: 0.1686 - accuracy: 0.9531 - val_loss: 0.6523 - val_accuracy: 0.8898\n",
      "Epoch 13/20\n",
      "16626/16626 [==============================] - 53s 3ms/sample - loss: 0.1612 - accuracy: 0.9579 - val_loss: 0.6760 - val_accuracy: 0.8999\n",
      "Epoch 14/20\n",
      "16626/16626 [==============================] - 53s 3ms/sample - loss: 0.1511 - accuracy: 0.9601 - val_loss: 0.7928 - val_accuracy: 0.8898\n",
      "Epoch 15/20\n",
      "16626/16626 [==============================] - 53s 3ms/sample - loss: 0.1387 - accuracy: 0.9646 - val_loss: 0.7528 - val_accuracy: 0.8875\n",
      "Epoch 16/20\n",
      "16626/16626 [==============================] - 53s 3ms/sample - loss: 0.1363 - accuracy: 0.9659 - val_loss: 0.9351 - val_accuracy: 0.8976\n",
      "Epoch 17/20\n",
      "16626/16626 [==============================] - 53s 3ms/sample - loss: 0.1401 - accuracy: 0.9674 - val_loss: 0.9233 - val_accuracy: 0.8830\n",
      "Epoch 18/20\n",
      "16626/16626 [==============================] - 62s 4ms/sample - loss: 0.1274 - accuracy: 0.9708 - val_loss: 0.9051 - val_accuracy: 0.9021\n",
      "Epoch 19/20\n",
      "16626/16626 [==============================] - 53s 3ms/sample - loss: 0.1297 - accuracy: 0.9694 - val_loss: 1.0521 - val_accuracy: 0.8976\n",
      "Epoch 20/20\n",
      "16626/16626 [==============================] - 53s 3ms/sample - loss: 0.1280 - accuracy: 0.9714 - val_loss: 1.0057 - val_accuracy: 0.8965\n",
      "937/937 [==============================] - 1s 657us/sample - loss: 1.0327 - accuracy: 0.8965\n",
      "[1.0327210271588596, 0.8964781216648879]\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x, train_y, epochs=20, batch_size=32, validation_data=(val_x, val_y))\n",
    "first_score = model.evaluate(test_x, test_y)\n",
    "print(first_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 22, 22, 28)        1400      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 11, 11, 28)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3388)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                216896    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 218,946\n",
      "Trainable params: 218,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(28, (7, 7), input_shape=(28, 28, 1,)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "    \n",
    "model.compile(optimizer=\"rmsprop\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16626 samples, validate on 889 samples\n",
      "Epoch 1/20\n",
      "16626/16626 [==============================] - 9s 523us/sample - loss: 0.4744 - accuracy: 0.8640 - val_loss: 0.3240 - val_accuracy: 0.9010\n",
      "Epoch 2/20\n",
      "16626/16626 [==============================] - 8s 483us/sample - loss: 0.2802 - accuracy: 0.9189 - val_loss: 0.2926 - val_accuracy: 0.9078\n",
      "Epoch 3/20\n",
      "16626/16626 [==============================] - 8s 488us/sample - loss: 0.2137 - accuracy: 0.9370 - val_loss: 0.2969 - val_accuracy: 0.9156\n",
      "Epoch 4/20\n",
      "16626/16626 [==============================] - 8s 490us/sample - loss: 0.1676 - accuracy: 0.9483 - val_loss: 0.2627 - val_accuracy: 0.9280\n",
      "Epoch 5/20\n",
      "16626/16626 [==============================] - 8s 489us/sample - loss: 0.1291 - accuracy: 0.9607 - val_loss: 0.2788 - val_accuracy: 0.9145\n",
      "Epoch 6/20\n",
      "16626/16626 [==============================] - 8s 480us/sample - loss: 0.1030 - accuracy: 0.9684 - val_loss: 0.2918 - val_accuracy: 0.9291\n",
      "Epoch 7/20\n",
      "16626/16626 [==============================] - 8s 487us/sample - loss: 0.0804 - accuracy: 0.9759 - val_loss: 0.3371 - val_accuracy: 0.9213\n",
      "Epoch 8/20\n",
      "16626/16626 [==============================] - 8s 500us/sample - loss: 0.0648 - accuracy: 0.9793 - val_loss: 0.3670 - val_accuracy: 0.9213\n",
      "Epoch 9/20\n",
      "16626/16626 [==============================] - 8s 481us/sample - loss: 0.0568 - accuracy: 0.9826 - val_loss: 0.3529 - val_accuracy: 0.9246\n",
      "Epoch 10/20\n",
      "16626/16626 [==============================] - 8s 495us/sample - loss: 0.0452 - accuracy: 0.9862 - val_loss: 0.3527 - val_accuracy: 0.9314\n",
      "Epoch 11/20\n",
      "16626/16626 [==============================] - 8s 488us/sample - loss: 0.0370 - accuracy: 0.9894 - val_loss: 0.3964 - val_accuracy: 0.9235\n",
      "Epoch 12/20\n",
      "16626/16626 [==============================] - 8s 487us/sample - loss: 0.0332 - accuracy: 0.9904 - val_loss: 0.3777 - val_accuracy: 0.9325\n",
      "Epoch 13/20\n",
      "16626/16626 [==============================] - 8s 487us/sample - loss: 0.0292 - accuracy: 0.9921 - val_loss: 0.4319 - val_accuracy: 0.9291\n",
      "Epoch 14/20\n",
      "16626/16626 [==============================] - 8s 485us/sample - loss: 0.0249 - accuracy: 0.9928 - val_loss: 0.4752 - val_accuracy: 0.9269\n",
      "Epoch 15/20\n",
      "16626/16626 [==============================] - 8s 482us/sample - loss: 0.0225 - accuracy: 0.9941 - val_loss: 0.4715 - val_accuracy: 0.9235\n",
      "Epoch 16/20\n",
      "16626/16626 [==============================] - 8s 483us/sample - loss: 0.0207 - accuracy: 0.9950 - val_loss: 0.4963 - val_accuracy: 0.9258\n",
      "Epoch 17/20\n",
      "16626/16626 [==============================] - 8s 486us/sample - loss: 0.0206 - accuracy: 0.9946 - val_loss: 0.4864 - val_accuracy: 0.9291\n",
      "Epoch 18/20\n",
      "16626/16626 [==============================] - 8s 485us/sample - loss: 0.0181 - accuracy: 0.9960 - val_loss: 0.5399 - val_accuracy: 0.9314\n",
      "Epoch 19/20\n",
      "16626/16626 [==============================] - 8s 490us/sample - loss: 0.0152 - accuracy: 0.9963 - val_loss: 0.5323 - val_accuracy: 0.9314\n",
      "Epoch 20/20\n",
      "16626/16626 [==============================] - 8s 492us/sample - loss: 0.0154 - accuracy: 0.9965 - val_loss: 0.5354 - val_accuracy: 0.9303\n",
      "937/937 [==============================] - 0s 181us/sample - loss: 0.7626 - accuracy: 0.9210\n",
      "[0.7626473953562087, 0.9210245464247598]\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x, train_y, epochs=20, batch_size=32, validation_data=(val_x, val_y))\n",
    "second_score = model.evaluate(test_x, test_y)\n",
    "print(second_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 120)               48120     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 84)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='tanh', input_shape=(28, 28, 1), padding=\"same\"),\n",
    "    AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
    "    Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid'),\n",
    "    AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
    "    Flatten(),\n",
    "    Dense(120, activation=\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(84, activation=\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16626 samples, validate on 889 samples\n",
      "Epoch 1/20\n",
      "16626/16626 [==============================] - 9s 545us/sample - loss: 0.9443 - accuracy: 0.6955 - val_loss: 0.4432 - val_accuracy: 0.8751\n",
      "Epoch 2/20\n",
      "16626/16626 [==============================] - 9s 512us/sample - loss: 0.5193 - accuracy: 0.8515 - val_loss: 0.3681 - val_accuracy: 0.8931\n",
      "Epoch 3/20\n",
      "16626/16626 [==============================] - 8s 507us/sample - loss: 0.4484 - accuracy: 0.8701 - val_loss: 0.3139 - val_accuracy: 0.9010\n",
      "Epoch 4/20\n",
      "16626/16626 [==============================] - 8s 500us/sample - loss: 0.4067 - accuracy: 0.8801 - val_loss: 0.2934 - val_accuracy: 0.9111\n",
      "Epoch 5/20\n",
      "16626/16626 [==============================] - 9s 512us/sample - loss: 0.3766 - accuracy: 0.8877 - val_loss: 0.3088 - val_accuracy: 0.9078\n",
      "Epoch 6/20\n",
      "16626/16626 [==============================] - 8s 510us/sample - loss: 0.3608 - accuracy: 0.8918 - val_loss: 0.2938 - val_accuracy: 0.9078\n",
      "Epoch 7/20\n",
      "16626/16626 [==============================] - 8s 506us/sample - loss: 0.3387 - accuracy: 0.9002 - val_loss: 0.2751 - val_accuracy: 0.9213\n",
      "Epoch 8/20\n",
      "16626/16626 [==============================] - 8s 502us/sample - loss: 0.3299 - accuracy: 0.9007 - val_loss: 0.2883 - val_accuracy: 0.9168\n",
      "Epoch 9/20\n",
      "16626/16626 [==============================] - 8s 503us/sample - loss: 0.3160 - accuracy: 0.9070 - val_loss: 0.2594 - val_accuracy: 0.9168\n",
      "Epoch 10/20\n",
      "16626/16626 [==============================] - 8s 501us/sample - loss: 0.3063 - accuracy: 0.9091 - val_loss: 0.2586 - val_accuracy: 0.9156\n",
      "Epoch 11/20\n",
      "16626/16626 [==============================] - 8s 502us/sample - loss: 0.2997 - accuracy: 0.9109 - val_loss: 0.2600 - val_accuracy: 0.9224\n",
      "Epoch 12/20\n",
      "16626/16626 [==============================] - 8s 508us/sample - loss: 0.2862 - accuracy: 0.9136 - val_loss: 0.2578 - val_accuracy: 0.9235\n",
      "Epoch 13/20\n",
      "16626/16626 [==============================] - 8s 510us/sample - loss: 0.2762 - accuracy: 0.9143 - val_loss: 0.2302 - val_accuracy: 0.9314\n",
      "Epoch 14/20\n",
      "16626/16626 [==============================] - 9s 512us/sample - loss: 0.2739 - accuracy: 0.9159 - val_loss: 0.2236 - val_accuracy: 0.9359\n",
      "Epoch 15/20\n",
      "16626/16626 [==============================] - 8s 499us/sample - loss: 0.2614 - accuracy: 0.9170 - val_loss: 0.2475 - val_accuracy: 0.9235\n",
      "Epoch 16/20\n",
      "16626/16626 [==============================] - 8s 499us/sample - loss: 0.2549 - accuracy: 0.9190 - val_loss: 0.2550 - val_accuracy: 0.9246\n",
      "Epoch 17/20\n",
      "16626/16626 [==============================] - 8s 507us/sample - loss: 0.2526 - accuracy: 0.9207 - val_loss: 0.2303 - val_accuracy: 0.9314\n",
      "Epoch 18/20\n",
      "16626/16626 [==============================] - 8s 502us/sample - loss: 0.2420 - accuracy: 0.9248 - val_loss: 0.2249 - val_accuracy: 0.9359\n",
      "Epoch 19/20\n",
      "16626/16626 [==============================] - 8s 507us/sample - loss: 0.2439 - accuracy: 0.9243 - val_loss: 0.2326 - val_accuracy: 0.9246\n",
      "Epoch 20/20\n",
      "16626/16626 [==============================] - 8s 507us/sample - loss: 0.2368 - accuracy: 0.9252 - val_loss: 0.2432 - val_accuracy: 0.9280\n",
      "937/937 [==============================] - 0s 269us/sample - loss: 0.2371 - accuracy: 0.9253\n",
      "[0.23714872700928136, 0.9252934898612594]\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x, train_y, epochs=20, batch_size=32, validation_data=(val_x, val_y))\n",
    "third_score = model.evaluate(test_x, test_y)\n",
    "print(third_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar([\"Just conv\", \"Conv + pooling\", \"LeNet-5\"], [first_score[0], second_score[0], third_score[0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
